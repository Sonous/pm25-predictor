# Data Cleaning Process - PM2.5 Prediction Project (Hong Kong Data)

## T·ªïng quan

T√†i li·ªáu n√†y m√¥ t·∫£ chi ti·∫øt quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu cho d·ª± √°n d·ª± ƒëo√°n ch·ªâ s·ªë PM2.5 s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ **c√°c tr·∫°m quan tr·∫Øc Hong Kong** v·ªõi ng∆∞·ª°ng outlier theo ti√™u chu·∫©n **WHO & EPA qu·ªëc t·∫ø**.

---

## üìã M·ª•c ti√™u

1. **Lo·∫°i b·ªè outliers** - Theo ti√™u chu·∫©n WHO/EPA ƒë·ªÉ ph√π h·ª£p v·ªõi d·ªØ li·ªáu Hong Kong
2. **X·ª≠ l√Ω missing values** - Imputation cho c√°c features (KH√îNG impute target variable)
3. **ƒê·∫£m b·∫£o data quality** - D·ªØ li·ªáu s·∫°ch, nh·∫•t qu√°n cho vi·ªác training model

---

## üîÑ Quy tr√¨nh L√†m s·∫°ch

### B∆∞·ªõc 1: Lo·∫°i b·ªè Outliers - WHO/EPA International Standards

**M·ª•c ƒë√≠ch:** Lo·∫°i b·ªè c√°c gi√° tr·ªã c·ª±c ƒëoan theo ti√™u chu·∫©n qu·ªëc t·∫ø tr∆∞·ªõc khi imputation.

#### 1.1. Target Variable (PM2.5)

```python
# PM2.5 l√† TARGET - PH·∫¢I c√≥ gi√° tr·ªã th·∫≠t
(F.col("PM2_5").isNotNull()) &
(F.col("PM2_5") >= 0) &
(F.col("PM2_5") < 250)  # WHO Emergency threshold
```

**L√Ω do:**

- PM2.5 l√† bi·∫øn c·∫ßn d·ª± ƒëo√°n (target)
- Impute PM2.5 = t·∫°o fake training data ‚Üí model h·ªçc sai
- **Gi·∫£i ph√°p:** Lo·∫°i b·ªè ho√†n to√†n records c√≥ PM2.5 = null

**Ng∆∞·ª°ng:** [0, 250) Œºg/m¬≥

**C∆° s·ªü khoa h·ªçc WHO/EPA:**

- **Gi√° tr·ªã √¢m:** Kh√¥ng h·ª£p l√Ω v·ªÅ m·∫∑t v·∫≠t l√Ω (l·ªói sensor/thu th·∫≠p d·ªØ li·ªáu)
- **Gi√° tr·ªã ‚â• 250 Œºg/m¬≥:** D·ª±a tr√™n ti√™u chu·∫©n qu·ªëc t·∫ø uy t√≠n:
  - **WHO Air Quality Guidelines (2021):** Emergency threshold 250 Œºg/m¬≥
  - **US EPA AQI:** PM2.5 250.5-350.4 Œºg/m¬≥ = "Hazardous"
  - **Hong Kong context:** Ph√π h·ª£p v·ªõi pollution episodes trong ƒë√¥ th·ªã ch√¢u √Å
  - **Ng∆∞·ª°ng 250:** WHO emergency level - lo·∫°i b·ªè measurement errors nh∆∞ng gi·ªØ pollution events th·ª±c t·∫ø

#### 1.2. Feature Variables (Pollutants)

```python
# Features: Cho ph√©p null, ch·ªâ lo·∫°i outliers theo WHO/EPA/EU standards
((F.col("PM10").isNull()) | ((F.col("PM10") >= 0) & (F.col("PM10") < 430)))  # WHO Emergency: 430 Œºg/m¬≥
((F.col("NO2").isNull()) | ((F.col("NO2") >= 0) & (F.col("NO2") < 400)))     # WHO/EU: 400 Œºg/m¬≥ (1-hour)
((F.col("SO2").isNull()) | ((F.col("SO2") >= 0) & (F.col("SO2") < 500)))     # WHO/EU: 500 Œºg/m¬≥ (10-min)
```

**L√Ω do:**

- Features ƒë∆∞·ª£c ph√©p null ‚Üí s·∫Ω impute ·ªü b∆∞·ªõc sau
- Ch·ªâ lo·∫°i b·ªè gi√° tr·ªã outliers c·ª±c ƒëoan theo ti√™u chu·∫©n qu·ªëc t·∫ø uy t√≠n

**Ng∆∞·ª°ng WHO/EPA/EU cho Hong Kong:**

- **PM10:** [0, 430) Œºg/m¬≥

  - **WHO Air Quality Guidelines (2021):** Emergency threshold 430 Œºg/m¬≥
  - **US EPA AQI:** PM10 425+ Œºg/m¬≥ = "Hazardous"
  - **Hong Kong context:** Ph√π h·ª£p v·ªõi dust storms v√† construction activities
  - **Ng∆∞·ª°ng 430:** WHO emergency level cho urban environment

- **NO2:** [0, 400) Œºg/m¬≥

  - **WHO Air Quality Guidelines (2021):** 400 Œºg/m¬≥ (1-hour guideline value)
  - **EU Directive 2008/50/EC:** 400 Œºg/m¬≥ (1-hour limit value)
  - **US EPA Standard:** ~376 Œºg/m¬≥ (200 ppb conversion)
  - **Hong Kong context:** Ph√π h·ª£p v·ªõi traffic emissions cao
  - **Ng∆∞·ª°ng 400:** Consensus gi·ªØa WHO v√† EU standards

- **SO2:** [0, 500) Œºg/m¬≥
  - **WHO Air Quality Guidelines (2021):** 500 Œºg/m¬≥ (10-minute guideline value)
  - **EU Directive 2008/50/EC:** 500 Œºg/m¬≥ (10-minute limit value)
  - **Hong Kong context:** Industrial v√† shipping emissions
  - **Ng∆∞·ª°ng 500:** International consensus cho emergency levels

#### 1.3. Weather Features

```python
# Precipitation: Ph·∫£i c√≥ gi√° tr·ªã h·ª£p l·ªá
(F.col("precipitation") >= 0) & (F.col("precipitation") < 100)
```

**Ng∆∞·ª°ng:**

- **Precipitation:** [0, 100) mm
  - **C∆° s·ªü khoa h·ªçc:** L∆∞·ª£ng m∆∞a kh√¥ng th·ªÉ √¢m (kh√¥ng h·ª£p l√Ω v·ªÅ m·∫∑t v·∫≠t l√Ω)
  - **D·ªØ li·ªáu th·ª±c t·∫ø:** L∆∞·ª£ng m∆∞a 1 gi·ªù > 100mm = m∆∞a r·∫•t l·ªõn (hi·∫øm g·∫∑p)
  - **Tham kh·∫£o:** Theo ph√¢n lo·∫°i c·ªßa WMO (World Meteorological Organization):
    - Light rain: < 2.5 mm/h
    - Moderate rain: 2.5 - 10 mm/h
    - Heavy rain: 10 - 50 mm/h
    - Violent rain: > 50 mm/h
  - **Ng∆∞·ª°ng 100:** Lo·∫°i b·ªè gi√° tr·ªã c·ª±c ƒëoan/l·ªói sensor, gi·ªØ l·∫°i c·∫£ m∆∞a r·∫•t l·ªõn

---

### B∆∞·ªõc 2: Missing Value Imputation

**M·ª•c ƒë√≠ch:** ƒêi·ªÅn gi√° tr·ªã missing cho c√°c features s·ª≠ d·ª•ng Linear Interpolation.

#### 2.1. Chi·∫øn l∆∞·ª£c Imputation

**Columns c·∫ßn impute:**

```python
pollutant_cols = ["PM10", "NO2", "SO2"]  # ‚ö†Ô∏è KH√îNG bao g·ªìm PM2.5!
```

**Ph∆∞∆°ng ph√°p: True Linear Interpolation (Time-based)**

```
y = y‚ÇÅ + (y‚ÇÇ - y‚ÇÅ) √ó (t - t‚ÇÅ) / (t‚ÇÇ - t‚ÇÅ)
```

Trong ƒë√≥:

- `y‚ÇÅ`: Gi√° tr·ªã g·∫ßn nh·∫•t tr∆∞·ªõc ƒë√≥ (prev_value)
- `y‚ÇÇ`: Gi√° tr·ªã g·∫ßn nh·∫•t sau ƒë√≥ (next_value)
- `t‚ÇÅ`: Timestamp c·ªßa y‚ÇÅ (prev_time)
- `t‚ÇÇ`: Timestamp c·ªßa y‚ÇÇ (next_time)
- `t`: Timestamp hi·ªán t·∫°i (current_time)

#### 2.2. Implementation v·ªõi PySpark

**B∆∞·ªõc 2.2.1: T·∫°o Epoch Column**

```python
df_filled = df_filled.withColumn("epoch", F.col("datetime").cast("long"))
```

Chuy·ªÉn timestamp th√†nh s·ªë (epoch) ƒë·ªÉ t√≠nh kho·∫£ng c√°ch th·ªùi gian.

**B∆∞·ªõc 2.2.2: ƒê·ªãnh nghƒ©a Window Functions**

```python
# Window forward: T√¨m gi√° tr·ªã TR∆Ø·ªöC g·∫ßn nh·∫•t
w_forward = (
    Window.partitionBy("location_id")
    .orderBy("epoch")
    .rowsBetween(Window.unboundedPreceding, Window.currentRow)
)

# Window backward: T√¨m gi√° tr·ªã SAU g·∫ßn nh·∫•t
w_backward = (
    Window.partitionBy("location_id")
    .orderBy("epoch")
    .rowsBetween(Window.currentRow, Window.unboundedFollowing)
)
```

**Quan tr·ªçng:** `partitionBy("location_id")` ‚Üí Kh√¥ng n·ªôi suy ch√©o gi·ªØa c√°c locations!

**B∆∞·ªõc 2.2.3: T√¨m gi√° tr·ªã & timestamp tr∆∞·ªõc/sau**

```python
df_filled = (
    df_filled
    .withColumn(f"{col_name}_prev_value",
                F.last(col_name, True).over(w_forward))
    .withColumn(f"{col_name}_next_value",
                F.first(col_name, True).over(w_backward))
    .withColumn(f"{col_name}_prev_time",
                F.last(F.when(F.col(col_name).isNotNull(), F.col("epoch")), True).over(w_forward))
    .withColumn(f"{col_name}_next_time",
                F.first(F.when(F.col(col_name).isNotNull(), F.col("epoch")), True).over(w_backward))
)
```

**B∆∞·ªõc 2.2.4: T√≠nh to√°n Linear Interpolation**

```python
interpolated_value = (
    F.col(f"{col_name}_prev_value") +
    (F.col(f"{col_name}_next_value") - F.col(f"{col_name}_prev_value")) *
    ((F.col("epoch") - F.col(f"{col_name}_prev_time")) /
     (F.col(f"{col_name}_next_time") - F.col(f"{col_name}_prev_time")))
)
```

**B∆∞·ªõc 2.2.5: Logic ch·ªçn gi√° tr·ªã cu·ªëi c√πng**

```python
df_filled = df_filled.withColumn(
    col_name,
    F.when(F.col(col_name).isNotNull(), F.col(col_name))  # 1. Gi·ªØ nguy√™n n·∫øu c√≥ gi√° tr·ªã
     .when(
         # 2. Linear interpolation n·∫øu c√≥ c·∫£ prev & next
         (F.col(f"{col_name}_prev_value").isNotNull()) &
         (F.col(f"{col_name}_next_value").isNotNull()) &
         ((F.col(f"{col_name}_next_time") - F.col(f"{col_name}_prev_time")) != 0),
         interpolated_value
     )
     .when(F.col(f"{col_name}_prev_value").isNotNull(),
           F.col(f"{col_name}_prev_value"))  # 3. Forward fill
     .when(F.col(f"{col_name}_next_value").isNotNull(),
           F.col(f"{col_name}_next_value"))  # 4. Backward fill
     .otherwise(None)  # 5. V·∫´n null n·∫øu kh√¥ng c√≥ data
)
```

**Fallback Logic:**

1. **Gi·ªØ nguy√™n** - N·∫øu gi√° tr·ªã ƒë√£ t·ªìn t·∫°i
2. **Linear Interpolation** - N·∫øu c√≥ c·∫£ gi√° tr·ªã tr∆∞·ªõc & sau (v√† kh√¥ng chia 0)
3. **Forward Fill** - N·∫øu ch·ªâ c√≥ gi√° tr·ªã tr∆∞·ªõc
4. **Backward Fill** - N·∫øu ch·ªâ c√≥ gi√° tr·ªã sau
5. **Null** - N·∫øu kh√¥ng c√≥ gi√° tr·ªã n√†o xung quanh (r·∫•t hi·∫øm)

**B∆∞·ªõc 2.2.6: Clean up**

```python
# X√≥a c√°c c·ªôt ph·ª• ƒë·ªÉ gi·∫£m memory
df_filled = df_filled.drop(
    f"{col_name}_prev_value", f"{col_name}_next_value",
    f"{col_name}_prev_time", f"{col_name}_next_time"
)
```

---

## ‚úÖ K·∫øt qu·∫£

### Sau Outlier Removal:

- **PM2.5:** 0 nulls (100% records c√≥ gi√° tr·ªã th·∫≠t)
- **PM10, NO2, SO2:** C√≤n missing (~5-10%) ‚Üí C·∫ßn imputation

### Sau Interpolation:

- **PM2.5:** 0 nulls ‚úÖ (Target variable)
- **PM10:** 0 nulls ‚úÖ (Interpolated)
- **NO2:** 0 nulls ‚úÖ (Interpolated)
- **SO2:** 0 nulls ‚úÖ (Interpolated)

---

## üéØ ∆Øu ƒëi·ªÉm c·ªßa ph∆∞∆°ng ph√°p n√†y

### 1. **Ch√≠nh x√°c v·ªÅ m·∫∑t th·ªùi gian**

- S·ª≠ d·ª•ng kho·∫£ng c√°ch th·ªùi gian TH·ª∞C (epoch) thay v√¨ index
- Ph√π h·ª£p v·ªõi d·ªØ li·ªáu time series kh√¥ng ƒë·ªÅu (c√≥ b·ªè m·∫´u, l·ªách timestamp)

### 2. **An to√†n cho multi-location data**

- Window partition theo `location_id`
- KH√îNG BAO GI·ªú n·ªôi suy ch√©o gi·ªØa c√°c locations kh√°c nhau

### 3. **T·ªëi ∆∞u hi·ªáu nƒÉng**

- Native PySpark (kh√¥ng convert sang Pandas)
- Kh√¥ng c√≥ timeout issues
- Scalable cho big data

### 4. **Logic fallback th√¥ng minh**

- X·ª≠ l√Ω edge cases (ƒë·∫ßu/cu·ªëi chu·ªói d·ªØ li·ªáu)
- Forward/Backward fill t·ª± ƒë·ªông

### 5. **ƒê√∫ng v·ªÅ m·∫∑t khoa h·ªçc**

- Kh√¥ng impute target variable (tr√°nh data leakage)
- Linear interpolation ph√π h·ª£p v·ªõi air quality data (continuous)

---

## üöÄ T·ªëi ∆∞u h√≥a

### C·∫•u h√¨nh Spark

```python
spark = SparkSession.builder \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.python.worker.timeout", "600") \
    .config("spark.executor.heartbeatInterval", "60s") \
    .config("spark.network.timeout", "600s") \
    .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
    .getOrCreate()
```

### Caching Strategy

```python
# Cache sau outlier removal
df_filled = df_no_outliers.cache()

# Cache sau interpolation
df_filled = df_filled.cache()

# Trigger computation
count = df_filled.count()
```

---

## üìä So s√°nh v·ªõi c√°c ph∆∞∆°ng ph√°p kh√°c

| Ph∆∞∆°ng ph√°p                      | ∆Øu ƒëi·ªÉm                     | Nh∆∞·ª£c ƒëi·ªÉm                       | Ph√π h·ª£p                          |
| -------------------------------- | --------------------------- | -------------------------------- | -------------------------------- |
| **Forward Fill**                 | ƒê∆°n gi·∫£n, nhanh             | T·∫°o "b·∫≠c thang", kh√¥ng smooth    | ‚ùå Kh√¥ng ph√π h·ª£p v·ªõi time series |
| **Mean/Median**                  | ƒê∆°n gi·∫£n                    | M·∫•t th√¥ng tin temporal           | ‚ùå Kh√¥ng ph√π h·ª£p v·ªõi time series |
| **Pandas Interpolate**           | Ch√≠nh x√°c, nhi·ªÅu options    | Timeout khi convert Pandas‚ÜîSpark | ‚ö†Ô∏è Ch·ªâ d√πng cho small data       |
| **PySpark Linear Interpolation** | Ch√≠nh x√°c, scalable, stable | Ph·ª©c t·∫°p h∆°n                     | ‚úÖ **T·ªêT NH·∫§T**                  |

---

## üìù Best Practices

### ‚úÖ DO:

1. **Lo·∫°i b·ªè outliers TR∆Ø·ªöC KHI imputation**
2. **KH√îNG impute target variable** (PM2.5)
3. **Partition by location_id** ƒë·ªÉ tr√°nh cross-location interpolation
4. **S·ª≠ d·ª•ng epoch** cho time-based interpolation
5. **Cache strategically** ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng
6. **Verify results** sau m·ªói b∆∞·ªõc

### ‚ùå DON'T:

1. Impute target variable (data leakage)
2. N·ªôi suy ch√©o gi·ªØa c√°c locations
3. Convert to√†n b·ªô data sang Pandas (timeout)
4. B·ªè qua outliers (·∫£nh h∆∞·ªüng statistics)
5. S·ª≠ d·ª•ng forward fill cho time series data

---

## üîó References

### Ti√™u chu·∫©n ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠

1. **WHO Air Quality Guidelines (2021)**

   - Link: https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health
   - PM2.5: 15 Œºg/m¬≥ (24-hour mean), 5 Œºg/m¬≥ (annual mean)
   - PM10: 45 Œºg/m¬≥ (24-hour mean), 15 Œºg/m¬≥ (annual mean)
   - NO2: 25 Œºg/m¬≥ (24-hour mean), 10 Œºg/m¬≥ (annual mean)
   - SO2: 40 Œºg/m¬≥ (24-hour mean)

2. **US EPA Air Quality Index (AQI)**

   - Link: https://www.airnow.gov/aqi/aqi-basics/
   - PM2.5 breakpoints:
     - 0-12.0: Good (green)
     - 12.1-35.4: Moderate (yellow)
     - 35.5-55.4: Unhealthy for Sensitive Groups (orange)
     - 55.5-150.4: Unhealthy (red)
     - 150.5-250.4: Very Unhealthy (purple)
     - 250.5+: Hazardous (maroon)

3. **Vietnam QCVN 05:2013/BTNMT**

   - Quy chu·∫©n k·ªπ thu·∫≠t qu·ªëc gia v·ªÅ ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ xung quanh
   - PM2.5: 50 Œºg/m¬≥ (24h trung b√¨nh)
   - PM10: 100 Œºg/m¬≥ (24h trung b√¨nh)
   - NO2: 200 Œºg/m¬≥ (1 gi·ªù)
   - SO2: 350 Œºg/m¬≥ (1 gi·ªù)

4. **World Meteorological Organization (WMO)**
   - Link: https://public.wmo.int/
   - Ph√¢n lo·∫°i c∆∞·ªùng ƒë·ªô m∆∞a theo mm/h

### K·ªπ thu·∫≠t x·ª≠ l√Ω d·ªØ li·ªáu

- **PySpark Window Functions:** https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/window.html
- **Linear Interpolation:** Standard method for time series imputation
- **Data Leakage Prevention:** Don't impute target variables in ML

### D·ªØ li·ªáu OpenAQ

- **OpenAQ Platform:** https://openaq.org/
- Ngu·ªìn d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ to√†n c·∫ßu m·ªü
- D·ªØ li·ªáu t·ª´ c√°c tr·∫°m monitoring t·∫°i Vi·ªát Nam

---

## üìå Notes

- D·ªØ li·ªáu sau khi clean ƒë∆∞·ª£c l∆∞u t·∫°i: `data/processed/pm25_data_all_locations.parquet`
- Total records: ~100,000+ (14 locations √ó ~7,000 records/location)
- Missing rate gi·∫£m t·ª´ ~8% xu·ªëng 0% cho t·∫•t c·∫£ pollutant features
- PM2.5 (target): 100% gi√° tr·ªã th·∫≠t (kh√¥ng c√≥ imputation)

---

_Last updated: November 7, 2025_

{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13948211,"sourceType":"datasetVersion","datasetId":8737649}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# C√†i ƒë·∫∑t l·∫°i protobuf ƒë·ªÉ s·ª≠a l·ªói xung ƒë·ªôt v·ªõi TensorFlow tr√™n Kaggle\n!pip install protobuf==3.20.3","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:24:39.244492Z","iopub.execute_input":"2025-12-03T01:24:39.245024Z","iopub.status.idle":"2025-12-03T01:24:45.838267Z","shell.execute_reply.started":"2025-12-03T01:24:39.244988Z","shell.execute_reply":"2025-12-03T01:24:45.837342Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport gc \n\nBASE_PATH = '/kaggle/input/preprocessed-hong-kong-pollutant-dataset/processed/xgboost'\nTARGET_COL = 'PM2_5_log_scaled'  ","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:24:49.674277Z","iopub.execute_input":"2025-12-03T01:24:49.674796Z","iopub.status.idle":"2025-12-03T01:24:50.944413Z","shell.execute_reply.started":"2025-12-03T01:24:49.674762Z","shell.execute_reply":"2025-12-03T01:24:50.943644Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def load_data_from_folder(base_path, split_name):\n    path_pattern = os.path.join(base_path, split_name, \"part-*\")\n    all_files = glob.glob(path_pattern)\n    \n    # L·ªçc file h·ª£p l·ªá\n    data_files = [f for f in all_files if \"part-\" in f and not f.endswith(\".crc\")]\n    data_files.sort()\n    \n    print(f\"--> ƒêang x·ª≠ l√Ω {len(data_files)} file trong '{split_name}'...\")\n    \n    df_list = []\n    for f in data_files:\n        try:\n            # ∆Øu ti√™n ƒë·ªçc parquet\n            if f.endswith('.parquet'):\n                df = pd.read_parquet(f)\n            else:\n                df = pd.read_csv(f)\n            df_list.append(df)\n        except Exception as e:\n            print(f\"  ‚ùå L·ªói file {os.path.basename(f)}: {e}\")\n\n    if not df_list:\n        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!\")\n        return None\n        \n    return pd.concat(df_list, ignore_index=True)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:24:54.036173Z","iopub.execute_input":"2025-12-03T01:24:54.037011Z","iopub.status.idle":"2025-12-03T01:24:54.042168Z","shell.execute_reply.started":"2025-12-03T01:24:54.036987Z","shell.execute_reply":"2025-12-03T01:24:54.041653Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def prepare_tabular_data(df, target_col):\n    \"\"\"\n    Chu·∫©n b·ªã d·ªØ li·ªáu tabular cho XGBoost.\n    Input: DataFrame v·ªõi c√°c c·ªôt feature v√† target.\n    Output X: (Samples, Features) \n    Output y: (Samples,)\n    \"\"\"\n    # 1. L·∫•y nh√£n y (Float32 ƒë·ªÉ ti·∫øt ki·ªám RAM)\n    y = df[target_col].values.astype(np.float32)\n    \n    # 2. T√¨m c√°c c·ªôt feature (lo·∫°i tr·ª´ target v√† c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt)\n    exclude_cols = [target_col, 'location_id', 'datetime']\n    feature_cols = [col for col in df.columns if col not in exclude_cols]\n    \n    print(f\"S·ªë l∆∞·ª£ng features: {len(feature_cols)}\")\n    print(f\"Target column: {target_col}\")\n    \n    # 3. L·∫•y features X\n    X = df[feature_cols].values.astype(np.float32)\n    \n    return X, y, len(feature_cols)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:24:56.542164Z","iopub.execute_input":"2025-12-03T01:24:56.542429Z","iopub.status.idle":"2025-12-03T01:24:56.547568Z","shell.execute_reply.started":"2025-12-03T01:24:56.542409Z","shell.execute_reply":"2025-12-03T01:24:56.546900Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 1. Load Train & Val\nprint(\"--- STEP 1: LOADING DATA ---\")\ndf_train = load_data_from_folder(BASE_PATH, 'train')\ndf_val   = load_data_from_folder(BASE_PATH, 'val')\n\n# 2. Chu·∫©n b·ªã d·ªØ li·ªáu tabular cho XGBoost\nprint(\"\\n--- STEP 2: PREPARING TABULAR DATA ---\")\nX_train, y_train, n_feats = prepare_tabular_data(df_train, TARGET_COL)\nX_val, y_val, _           = prepare_tabular_data(df_val, TARGET_COL)\n\nprint(f\"Input Shape XGBoost: {X_train.shape}\")\nprint(f\"Target Shape: {y_train.shape}\")\nprint(f\"Validation Shape: {X_val.shape}\")\n\n# 3. X√≥a DataFrame g·ªëc ƒë·ªÉ gi·∫£i ph√≥ng RAM\ndel df_train, df_val\ngc.collect()","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:25:00.903222Z","iopub.execute_input":"2025-12-03T01:25:00.903988Z","iopub.status.idle":"2025-12-03T01:25:01.912558Z","shell.execute_reply.started":"2025-12-03T01:25:00.903942Z","shell.execute_reply":"2025-12-03T01:25:01.911776Z"}},"outputs":[{"name":"stdout","text":"--- STEP 1: LOADING DATA ---\n--> ƒêang x·ª≠ l√Ω 7 file trong 'train'...\n--> ƒêang x·ª≠ l√Ω 7 file trong 'val'...\n\n--- STEP 2: PREPARING TABULAR DATA ---\nS·ªë l∆∞·ª£ng features: 71\nTarget column: PM2_5_log_scaled\nS·ªë l∆∞·ª£ng features: 71\nTarget column: PM2_5_log_scaled\nInput Shape XGBoost: (201818, 71)\nTarget Shape: (201818,)\nValidation Shape: (43061, 71)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# C·∫•u h√¨nh XGBoost\n# tree_method='hist': T·ªëi ∆∞u c·ª±c nhanh cho d·ªØ li·ªáu l·ªõn (t∆∞∆°ng t·ª± LightGBM)\n# device='cuda': N·∫øu b·∫°n b·∫≠t GPU th√¨ b·ªè comment d√≤ng n√†y ƒë·ªÉ ch·∫°y nhanh h∆°n\nmodel = XGBRegressor(\n    n_estimators=2000,      # S·ªë l∆∞·ª£ng c√¢y t·ªëi ƒëa\n    learning_rate=0.05,     # T·ªëc ƒë·ªô h·ªçc\n    max_depth=8,            # ƒê·ªô s√¢u c·ªßa c√¢y (ƒë·ª´ng ƒë·ªÉ qu√° s√¢u d·ªÖ overfitting)\n    subsample=0.8,          # Ch·ªâ d√πng 80% d·ªØ li·ªáu m·ªói l·∫ßn train (tr√°nh overfit)\n    colsample_bytree=0.8,   # Ch·ªâ d√πng 80% features m·ªói c√¢y\n    n_jobs=-1,              # D√πng t·∫•t c·∫£ CPU core\n    tree_method='hist',     # B·∫Øt bu·ªôc cho d·ªØ li·ªáu l·ªõn\n    early_stopping_rounds=50, # D·ª´ng n·∫øu kh√¥ng c·∫£i thi·ªán sau 50 v√≤ng\n    random_state=42\n    # device='cuda'         # <--- B·ªè comment n·∫øu b·∫≠t GPU T4 x2\n)\n\nprint(\"\\n--- STEP 3: TRAINING XGBOOST ---\")\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train), (X_val, y_val)],\n    verbose=100  # In log m·ªói 100 v√≤ng\n)\n\n# Sau khi train xong, x√≥a X_train, X_val ƒë·ªÉ l·∫•y ch·ªó cho Test\ndel X_train, y_train, X_val, y_val\ngc.collect()\nprint(\"üßπ ƒê√£ d·ªçn d·∫πp RAM sau khi train.\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:25:08.931440Z","iopub.execute_input":"2025-12-03T01:25:08.932133Z","iopub.status.idle":"2025-12-03T01:25:42.407252Z","shell.execute_reply.started":"2025-12-03T01:25:08.932109Z","shell.execute_reply":"2025-12-03T01:25:42.406666Z"}},"outputs":[{"name":"stdout","text":"\n--- STEP 3: TRAINING XGBOOST ---\n[0]\tvalidation_0-rmse:0.12379\tvalidation_1-rmse:0.11898\n[100]\tvalidation_0-rmse:0.02627\tvalidation_1-rmse:0.02940\n[200]\tvalidation_0-rmse:0.02406\tvalidation_1-rmse:0.02906\n[300]\tvalidation_0-rmse:0.02269\tvalidation_1-rmse:0.02900\n[400]\tvalidation_0-rmse:0.02155\tvalidation_1-rmse:0.02898\n[500]\tvalidation_0-rmse:0.02050\tvalidation_1-rmse:0.02897\n[518]\tvalidation_0-rmse:0.02035\tvalidation_1-rmse:0.02898\nüßπ ƒê√£ d·ªçn d·∫πp RAM sau khi train.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 1. Load Test\nprint(\"\\n--- STEP 4: TESTING ---\")\ndf_test = load_data_from_folder(BASE_PATH, 'test')\n\n# 2. Chu·∫©n b·ªã Test data cho XGBoost\n# L∆∞u √Ω: ƒê·∫£m b·∫£o prepare_tabular_data kh·ªõp v·ªõi c√°ch x·ª≠ l√Ω l√∫c train\nX_test, y_test, _ = prepare_tabular_data(df_test, TARGET_COL)\n\n# X√≥a ngay dataframe g·ªëc ƒë·ªÉ ti·∫øt ki·ªám RAM\ndel df_test\ngc.collect()\n\n# 3. D·ª± b√°o\nprint(\"ƒêang d·ª± b√°o...\")\ny_pred = model.predict(X_test)\n\n# 4. H√†m ƒë√°nh gi√° (ƒê√£ s·ª≠a ƒë·ªïi)\ndef evaluate(y_true, y_pred, name):\n    r2 = r2_score(y_true, y_pred)\n    \n    # T√≠nh MSE\n    mse = mean_squared_error(y_true, y_pred)\n    \n    # T√≠nh RMSE (L·∫•y cƒÉn b·∫≠c hai c·ªßa MSE)\n    rmse = np.sqrt(mse)\n    \n    mae = mean_absolute_error(y_true, y_pred)\n    \n    # ƒê√£ x√≥a ph·∫ßn t√≠nh MRE\n    \n    print(f\"\\n=== K·∫æT QU·∫¢ {name} ===\")\n    print(f\"R2 Score: {r2:.4f}\")\n    print(f\"MSE:      {mse:.4f}\")  # Hi·ªÉn th·ªã MSE\n    print(f\"RMSE:     {rmse:.4f}\")\n    print(f\"MAE:      {mae:.4f}\")\n\n# Ch·∫°y ƒë√°nh gi√°\nevaluate(y_test, y_pred, \"XGBoost Final Result\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:25:52.678393Z","iopub.execute_input":"2025-12-03T01:25:52.678685Z","iopub.status.idle":"2025-12-03T01:25:53.290179Z","shell.execute_reply.started":"2025-12-03T01:25:52.678659Z","shell.execute_reply":"2025-12-03T01:25:53.289322Z"}},"outputs":[{"name":"stdout","text":"\n--- STEP 4: TESTING ---\n--> ƒêang x·ª≠ l√Ω 7 file trong 'test'...\nS·ªë l∆∞·ª£ng features: 71\nTarget column: PM2_5_log_scaled\nƒêang d·ª± b√°o...\n\n=== K·∫æT QU·∫¢ XGBoost Final Result ===\nR2 Score: 0.9553\nMSE:      0.0009\nRMSE:     0.0298\nMAE:      0.0187\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# L∆∞u m√¥ h√¨nh XGBoost v√†o file .json\nmodel_name = 'xgboost_pm25.json' # ƒê·ªïi ƒëu√¥i file th√†nh .json\n\n# D√πng h√†m save_model c·ªßa XGBoost\nmodel.save_model(model_name) \n\nprint(f\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh th√†nh c√¥ng v√†o file: {model_name}\")\nprint(\"B·∫°n c√≥ th·ªÉ t√¨m th·∫•y n√≥ trong m·ª•c Output b√™n ph·∫£i ƒë·ªÉ t·∫£i v·ªÅ.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:26:04.178170Z","iopub.execute_input":"2025-12-03T01:26:04.178684Z","iopub.status.idle":"2025-12-03T01:26:04.330228Z","shell.execute_reply.started":"2025-12-03T01:26:04.178657Z","shell.execute_reply":"2025-12-03T01:26:04.329354Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh th√†nh c√¥ng v√†o file: xgboost_pm25.json\nB·∫°n c√≥ th·ªÉ t√¨m th·∫•y n√≥ trong m·ª•c Output b√™n ph·∫£i ƒë·ªÉ t·∫£i v·ªÅ.\n","output_type":"stream"}],"execution_count":8}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13803471,"sourceType":"datasetVersion","datasetId":8737649}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CÃ i Ä‘áº·t láº¡i protobuf Ä‘á»ƒ sá»­a lá»—i xung Ä‘á»™t vá»›i TensorFlow trÃªn Kaggle\n!pip install protobuf==3.20.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:05:04.952415Z","iopub.execute_input":"2025-12-03T01:05:04.952959Z","iopub.status.idle":"2025-12-03T01:05:11.454009Z","shell.execute_reply.started":"2025-12-03T01:05:04.952925Z","shell.execute_reply":"2025-12-03T01:05:11.453343Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Khai bÃ¡o thÆ° viá»‡n & Cáº¥u hÃ¬nh","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n (Trá» vÃ o thÆ° má»¥c LSTM)\nBASE_PATH = '/kaggle/input/preprocessed-hong-kong-pollutant-dataset/processed/lstm_sequences'\nTARGET_COL = 'target_value'  # TÃªn cá»™t má»¥c tiÃªu trong file parquet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:05:16.850215Z","iopub.execute_input":"2025-12-03T01:05:16.850842Z","iopub.status.idle":"2025-12-03T01:05:39.668227Z","shell.execute_reply.started":"2025-12-03T01:05:16.850812Z","shell.execute_reply":"2025-12-03T01:05:39.667622Z"}},"outputs":[{"name":"stderr","text":"2025-12-03 01:05:20.618699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764723920.973348      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764723921.086757      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# HÃ m Ä‘á»c dá»¯ liá»‡u","metadata":{}},{"cell_type":"code","source":"def load_data_from_folder(base_path, split_name):\n    \"\"\"Äá»c táº¥t cáº£ file part-*.parquet trong thÆ° má»¥c\"\"\"\n    path_pattern = os.path.join(base_path, split_name, \"part-*\")\n    all_files = glob.glob(path_pattern)\n    \n    # Lá»c file há»£p lá»‡\n    data_files = [f for f in all_files if \"part-\" in f and not f.endswith(\".crc\")]\n    data_files.sort()\n    \n    print(f\"--> Äang xá»­ lÃ½ {len(data_files)} file trong '{split_name}'...\")\n    \n    df_list = []\n    for f in data_files:\n        try:\n            # Æ¯u tiÃªn Ä‘á»c parquet\n            if f.endswith('.parquet'):\n                df = pd.read_parquet(f)\n            else:\n                df = pd.read_csv(f)\n            df_list.append(df)\n        except Exception as e:\n            print(f\"  âŒ Lá»—i file {os.path.basename(f)}: {e}\")\n\n    if not df_list:\n        print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u!\")\n        return None\n        \n    # Gá»™p cÃ¡c file láº¡i\n    df = pd.concat(df_list, ignore_index=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:05:46.026791Z","iopub.execute_input":"2025-12-03T01:05:46.027310Z","iopub.status.idle":"2025-12-03T01:05:46.033622Z","shell.execute_reply.started":"2025-12-03T01:05:46.027284Z","shell.execute_reply":"2025-12-03T01:05:46.032930Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# HÃ m xá»­ lÃ½ Sequence","metadata":{}},{"cell_type":"code","source":"def prepare_3d_data(df, target_col):\n    \"\"\"\n    PhiÃªn báº£n tá»‘i Æ°u bá»™ nhá»›: Sá»­ dá»¥ng float32\n    \"\"\"\n    # 1. TÃ¡ch nhÃ£n (y)\n    y = df[target_col].values.astype(np.float32) # <--- Ã‰p kiá»ƒu float32\n    \n    # 2. TÃ¬m cÃ¡c cá»™t feature\n    feature_cols = [c for c in df.columns if c.endswith('_sequence')]\n    \n    # 3. Xáº¿p chá»“ng cÃ¡c máº£ng láº¡i\n    x_list = []\n    for col in feature_cols:\n        # Chuyá»ƒn list of arrays thÃ nh matrix\n        col_data = np.stack(df[col].tolist())\n        x_list.append(col_data)\n    \n    # Gá»™p láº¡i vÃ  Ã©p kiá»ƒu float32 ngay láº­p tá»©c\n    X = np.stack(x_list, axis=2).astype(np.float32) # <--- QUAN TRá»ŒNG: Giáº£m 50% RAM\n    \n    return X, y, feature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:05:49.350577Z","iopub.execute_input":"2025-12-03T01:05:49.351125Z","iopub.status.idle":"2025-12-03T01:05:49.356350Z","shell.execute_reply.started":"2025-12-03T01:05:49.351101Z","shell.execute_reply":"2025-12-03T01:05:49.355565Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Thá»±c thi Load & Xá»­ lÃ½","metadata":{}},{"cell_type":"code","source":"import gc # ThÆ° viá»‡n dá»n rÃ¡c bá»™ nhá»›\n\n# --- GIAI ÄOáº N 1: HUáº¤N LUYá»†N ---\n\n# 1. Chá»‰ Load Train vÃ  Val (KHÃ”NG LOAD TEST LÃšC NÃ€Y)\nprint(\"Step 1: Loading Train & Val data...\")\ndf_train = load_data_from_folder(BASE_PATH, 'train')\ndf_val   = load_data_from_folder(BASE_PATH, 'val')\n\n# 2. Convert sang 3D (Float32)\nprint(\"Step 2: Converting to 3D Tensor...\")\nX_train, y_train, feats = prepare_3d_data(df_train, TARGET_COL)\nX_val, y_val, _         = prepare_3d_data(df_val, TARGET_COL)\n\n# Láº¥y thÃ´ng sá»‘ shape\nn_timesteps = X_train.shape[1]\nn_features = X_train.shape[2]\nprint(f\"Structure: {X_train.shape}\")\n\n# XÃ³a dataframe gá»‘c Ä‘á»ƒ tiáº¿t kiá»‡m RAM ngay láº­p tá»©c\ndel df_train, df_val\ngc.collect()\n\n# 3. XÃ¢y dá»±ng Model\nprint(\"Step 3: Training Model...\")\nmodel = Sequential()\nmodel.add(Input(shape=(n_timesteps, n_features)))\nmodel.add(LSTM(64, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer='adam', loss='mse')\n\n# 4. Train\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=50,\n    batch_size=64,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stop],\n    verbose=1\n)\n\n# 5. Dá»ŒN Dáº¸P Bá»˜ NHá»š Cá»°C Máº NH (QUAN TRá»ŒNG NHáº¤T)\nprint(\"Step 4: Cleaning up memory...\")\n# XÃ³a sáº¡ch dá»¯ liá»‡u Train/Val khá»i RAM\ndel X_train, y_train, X_val, y_val\n# Ã‰p dá»n rÃ¡c\ngc.collect()\nprint(\"ğŸ§¹ RAM Ä‘Ã£ Ä‘Æ°á»£c giáº£i phÃ³ng! Sáºµn sÃ ng cho bÆ°á»›c Test.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:05:53.522109Z","iopub.execute_input":"2025-12-03T01:05:53.522398Z","iopub.status.idle":"2025-12-03T01:15:09.713331Z","shell.execute_reply.started":"2025-12-03T01:05:53.522376Z","shell.execute_reply":"2025-12-03T01:15:09.712754Z"}},"outputs":[{"name":"stdout","text":"Step 1: Loading Train & Val data...\n--> Äang xá»­ lÃ½ 8 file trong 'train'...\n--> Äang xá»­ lÃ½ 7 file trong 'val'...\nStep 2: Converting to 3D Tensor...\nStructure: (201482, 24, 18)\nStep 3: Training Model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764723964.512055      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1764723964.512672      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764723970.127283     127 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - loss: 0.0116 - val_loss: 0.0027\nEpoch 2/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0024\nEpoch 3/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0024\nEpoch 4/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0023\nEpoch 5/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0024\nEpoch 6/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0023\nEpoch 7/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 8/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 9/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 10/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0024\nEpoch 11/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 12/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 13/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0023\nEpoch 14/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 15/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 16/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 17/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 18/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 19/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 20/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 21/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0024\nEpoch 22/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 23/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0023\nEpoch 24/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0024\nEpoch 25/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0024\nEpoch 26/50\n\u001b[1m3149/3149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0024\nStep 4: Cleaning up memory...\nğŸ§¹ RAM Ä‘Ã£ Ä‘Æ°á»£c giáº£i phÃ³ng! Sáºµn sÃ ng cho bÆ°á»›c Test.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ÄÃ¡nh giÃ¡","metadata":{}},{"cell_type":"code","source":"# --- GIAI ÄOáº N 2: Dá»° BÃO ---\n\n# 1. BÃ¢y giá» má»›i load táº­p Test\nprint(\"Step 5: Loading Test data...\")\ndf_test = load_data_from_folder(BASE_PATH, 'test')\n\n# 2. Convert Test sang 3D\nX_test, y_test, _ = prepare_3d_data(df_test, TARGET_COL)\ndel df_test # XÃ³a luÃ´n df gá»‘c\ngc.collect()\n\n# 3. Dá»± bÃ¡o (Batch size lá»›n Ä‘á»ƒ cháº¡y nhanh hÆ¡n nhÆ°ng váº«n an toÃ n)\nprint(\"Step 6: Predicting...\")\ny_pred = model.predict(X_test, batch_size=128, verbose=1)\n\n# 4. ÄÃ¡nh giÃ¡\ndef evaluate(y_true, y_pred, name):\n    r2 = r2_score(y_true, y_pred)\n    \n    # TÃ­nh MSE\n    mse = mean_squared_error(y_true, y_pred)\n    \n    # TÃ­nh RMSE (cÃ³ thá»ƒ láº¥y cÄƒn báº­c hai cá»§a MSE luÃ´n)\n    rmse = np.sqrt(mse)\n    \n    mae = mean_absolute_error(y_true, y_pred)\n    \n    # ÄÃ£ xÃ³a pháº§n tÃ­nh MRE vÃ  epsilon vÃ¬ khÃ´ng dÃ¹ng ná»¯a\n    \n    print(f\"\\n=== Káº¾T QUáº¢ {name} ===\")\n    print(f\"R2 Score: {r2:.4f}\")\n    print(f\"MSE:      {mse:.4f}\")  # Hiá»ƒn thá»‹ MSE\n    print(f\"RMSE:     {rmse:.4f}\")\n    print(f\"MAE:      {mae:.4f}\")\n\nevaluate(y_test, y_pred, \"LSTM Final Result\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:15:36.718865Z","iopub.execute_input":"2025-12-03T01:15:36.719151Z","iopub.status.idle":"2025-12-03T01:15:39.999120Z","shell.execute_reply.started":"2025-12-03T01:15:36.719128Z","shell.execute_reply":"2025-12-03T01:15:39.998453Z"}},"outputs":[{"name":"stdout","text":"Step 5: Loading Test data...\n--> Äang xá»­ lÃ½ 7 file trong 'test'...\nStep 6: Predicting...\n\u001b[1m336/336\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n\n=== Káº¾T QUáº¢ LSTM Final Result ===\nR2 Score: 0.8782\nMSE:      0.0024\nRMSE:     0.0493\nMAE:      0.0334\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# LÆ°u mÃ´ hÃ¬nh LSTM vÃ o file .keras (Ä‘á»‹nh dáº¡ng chuáº©n má»›i cá»§a Keras)\nmodel_name = 'lstm_pm25.keras'\nmodel.save(model_name)\n\nprint(f\"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh thÃ nh cÃ´ng vÃ o file: {model_name}\")\nprint(\"Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y nÃ³ trong má»¥c Output bÃªn pháº£i Ä‘á»ƒ táº£i vá».\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:15:58.339690Z","iopub.execute_input":"2025-12-03T01:15:58.340322Z","iopub.status.idle":"2025-12-03T01:15:58.394940Z","shell.execute_reply.started":"2025-12-03T01:15:58.340294Z","shell.execute_reply":"2025-12-03T01:15:58.394321Z"}},"outputs":[{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh thÃ nh cÃ´ng vÃ o file: lstm_pm25.keras\nBáº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y nÃ³ trong má»¥c Output bÃªn pháº£i Ä‘á»ƒ táº£i vá».\n","output_type":"stream"}],"execution_count":7}]}